{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "authorship_tag": "UMKM Analytics"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä UMKM Analytics - Data Pipeline\n",
                "**100% FREE - Menggunakan Google Colab + BigQuery**\n",
                "\n",
                "Notebook ini menggantikan Cloud Functions yang memerlukan billing.\n",
                "\n",
                "## Fitur:\n",
                "- Upload data lokal ke BigQuery\n",
                "- ETL Pipeline\n",
                "- Generate Daily Summary\n",
                "- Sentiment Analysis dari Tokopedia Reviews"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup & Authentication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q google-cloud-bigquery pandas pyarrow db-dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Authenticate with Google Cloud\n",
                "from google.colab import auth\n",
                "auth.authenticate_user()\n",
                "\n",
                "print('‚úÖ Authenticated successfully!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "PROJECT_ID = 'ipsd-483408'  # Ganti dengan Project ID Anda\n",
                "DATASET_ID = 'umkm_analytics'\n",
                "LOCATION = 'asia-southeast2'\n",
                "\n",
                "from google.cloud import bigquery\n",
                "client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n",
                "\n",
                "print(f'‚úÖ Connected to BigQuery: {PROJECT_ID}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Upload Sample Data ke BigQuery"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Upload file dari local atau Google Drive\n",
                "from google.colab import files\n",
                "\n",
                "print('üìÅ Upload file transactions.csv')\n",
                "uploaded = files.upload()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dan preview data\n",
                "import io\n",
                "\n",
                "# Ambil nama file yang diupload\n",
                "filename = list(uploaded.keys())[0]\n",
                "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
                "\n",
                "print(f'üìä Total Records: {len(df)}')\n",
                "print(f'üìã Columns: {df.columns.tolist()}')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upload ke BigQuery\n",
                "table_id = f'{PROJECT_ID}.{DATASET_ID}.raw_sales'\n",
                "\n",
                "# Configure job\n",
                "job_config = bigquery.LoadJobConfig(\n",
                "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,  # Replace existing\n",
                "    autodetect=True,\n",
                ")\n",
                "\n",
                "# Upload\n",
                "job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
                "job.result()  # Wait for completion\n",
                "\n",
                "table = client.get_table(table_id)\n",
                "print(f'‚úÖ Uploaded {table.num_rows} rows to {table_id}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Upload Tokopedia Reviews"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('üìÅ Upload file tokopedia_product_reviews_2025.csv')\n",
                "uploaded_reviews = files.upload()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load reviews\n",
                "review_file = list(uploaded_reviews.keys())[0]\n",
                "df_reviews = pd.read_csv(io.BytesIO(uploaded_reviews[review_file]))\n",
                "\n",
                "print(f'üìä Total Reviews: {len(df_reviews)}')\n",
                "print(f'üìã Columns: {df_reviews.columns.tolist()}')\n",
                "\n",
                "# Sentiment distribution\n",
                "print('\\nüé≠ Sentiment Distribution:')\n",
                "print(df_reviews['sentiment_label'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upload reviews ke BigQuery\n",
                "reviews_table_id = f'{PROJECT_ID}.{DATASET_ID}.tokopedia_reviews'\n",
                "\n",
                "job = client.load_table_from_dataframe(df_reviews, reviews_table_id, job_config=job_config)\n",
                "job.result()\n",
                "\n",
                "table = client.get_table(reviews_table_id)\n",
                "print(f'‚úÖ Uploaded {table.num_rows} reviews to {reviews_table_id}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Generate Daily Summary (ETL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ETL Query: Generate Daily Summary\n",
                "etl_query = f'''\n",
                "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.daily_summary` AS\n",
                "SELECT \n",
                "    sale_date as summary_date,\n",
                "    COUNT(transaction_id) as total_transactions,\n",
                "    SUM(total_amount) as total_revenue,\n",
                "    SUM(quantity) as total_quantity,\n",
                "    ROUND(AVG(total_amount), 0) as avg_order_value,\n",
                "    ARRAY_AGG(category ORDER BY total_amount DESC LIMIT 1)[OFFSET(0)] as top_category,\n",
                "    ARRAY_AGG(product_name ORDER BY total_amount DESC LIMIT 1)[OFFSET(0)] as top_product,\n",
                "    COUNT(DISTINCT seller_name) as unique_sellers,\n",
                "    CURRENT_TIMESTAMP() as created_at\n",
                "FROM `{PROJECT_ID}.{DATASET_ID}.raw_sales`\n",
                "GROUP BY sale_date\n",
                "ORDER BY sale_date DESC\n",
                "'''\n",
                "\n",
                "job = client.query(etl_query)\n",
                "job.result()\n",
                "\n",
                "print('‚úÖ Daily summary generated!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview daily summary\n",
                "query = f'''\n",
                "SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.daily_summary`\n",
                "ORDER BY summary_date DESC\n",
                "LIMIT 10\n",
                "'''\n",
                "\n",
                "df_summary = client.query(query).to_dataframe()\n",
                "df_summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Analisis Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top Categories\n",
                "query = f'''\n",
                "SELECT \n",
                "    category,\n",
                "    COUNT(*) as transactions,\n",
                "    SUM(total_amount) as revenue\n",
                "FROM `{PROJECT_ID}.{DATASET_ID}.raw_sales`\n",
                "GROUP BY category\n",
                "ORDER BY revenue DESC\n",
                "'''\n",
                "\n",
                "df_categories = client.query(query).to_dataframe()\n",
                "\n",
                "# Visualize\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(df_categories['category'], df_categories['revenue']/1000000)\n",
                "plt.xlabel('Revenue (Juta Rupiah)')\n",
                "plt.title('Revenue per Kategori UMKM')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sentiment Analysis dari Tokopedia\n",
                "query = f'''\n",
                "SELECT \n",
                "    sentiment_label,\n",
                "    COUNT(*) as count,\n",
                "    ROUND(AVG(rating), 2) as avg_rating\n",
                "FROM `{PROJECT_ID}.{DATASET_ID}.tokopedia_reviews`\n",
                "GROUP BY sentiment_label\n",
                "'''\n",
                "\n",
                "df_sentiment = client.query(query).to_dataframe()\n",
                "\n",
                "# Pie chart\n",
                "plt.figure(figsize=(8, 8))\n",
                "colors = ['#4CAF50', '#FFC107', '#F44336']\n",
                "plt.pie(df_sentiment['count'], labels=df_sentiment['sentiment_label'], \n",
                "        autopct='%1.1f%%', colors=colors, startangle=90)\n",
                "plt.title('Sentiment Distribution - Tokopedia Reviews')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÖ Selesai!\n",
                "\n",
                "Data sudah tersimpan di BigQuery dan siap untuk:\n",
                "- Dibuat dashboard di Looker Studio\n",
                "- Dianalisis lebih lanjut\n",
                "- Di-export ke format lain"
            ]
        }
    ]
}